\chapter{User's guide} 
\label{chap:user} 

This section is generated automatically from \texttt{README.rst}, the same file that produces the \href{github.com/malaria-atlas-project/generic-mbg}{GitHub documentation}. 




The generic MBG package allows us to write PyMC probability models for each
project that works with some kind of spatial GLM, then turn the model over
to the project team for testing, fitting, mapping and experimentation using
three easy shell commands:
\begin{itemize}
\item {} 
\texttt{mbg-infer} runs the MCMC algorithm using the given model {\&} an input dataset,
stored in a csv file, and stores the traces in an HDF5 archive.

\item {} 
\texttt{mbg-map} takes the HDF5 archive produced by mbg-infer, and an ASCII file with
a MISSING entry in its header. Produces a set of bespoke summary maps on the grid
expressed by the ASCII header. The missing pixels are missing in the output also.

\item {} 
\texttt{mbg-validate} takes the HDF5 archive produced by mbg-infer and a 'holdout'
dataset, stored in a csv file, and creates a set of predictive samples at the
holdout locations and some validation plots.

\item {} 
\texttt{mbg-decluster} partitions a CSV datafile into 'kept' and 'holdout' portions.

\end{itemize}

If the project's members are interested in changing the model or specifying a
subjective prior, there are two additional shell commands available to help:
\begin{itemize}
\item {} 
\texttt{mbg-scalar-priors} draws samples from the prior for all scalar parameters
(including deterministics) and plots histograms for inspection.

\item {} 
\texttt{mbg-realize-prior} draws all scalar parameters from the prior, and realizes
and plots the random field on grids matching a number of input ASCIIs.

\item {} 
\texttt{mbg-describe-tracefile} provides information about the circumstances under which
traces were produced.

\end{itemize}

All shell commands can be run with only the \texttt{-h} option to print some help to the
screen. However, if you're reading this document, you don't really need to do that.


%___________________________________________________________________________



\section{Detailed usage instructions}
\label{sec:detailed-usage-instructions}

If you want to use the shell commands, this section is for you.


%___________________________________________________________________________



\subsection{\texttt{mbg-infer}}
\label{sec:mbg-infer}
\begin{quote}{\ttfamily \raggedright \noindent
mbg-infer~module~database-file~input~{[}options{]}
}\end{quote}

Produces the requested database file. Also produces plots of the dynamic traces of all
scalar parameters as PDF's, and saves them in the folder \texttt{name-plots}, where \texttt{name}
is the name of the database file. You will need to inspect these plots to determine how
many 'burnin' iterations should be discarded when making maps.

If you determine that more MCMC samples are needed, simply run mbg-infer with the same
database file argument to pick up where you left off and keep sampling.


%___________________________________________________________________________



\subsubsection{Required arguments}
\label{sec:required-arguments}
\newcounter{listcnt0}
\begin{list}{\arabic{listcnt0}.}
{
\usecounter{listcnt0}
\setlength{\rightmargin}{\leftmargin}
}
\item {} 
The name of the module containing the model specification.

\item {} 
The name of the database file to be produced. If you do not want it to go in the current
directory, specify a path, eg \texttt{/home/anand/traces/run-01-04-2009}. If the database file
already exists, you will be prompted about whether you want to continue sampling into it
or remove it.

\item {} 
The name of a csv file containing the input data. If it is a different directory, specify
the path to it, eg \texttt{/home/anand/data/query-01-04-2009.csv}. This csv file must have the
following columns:
\begin{itemize}
\item {} 
\texttt{lon}, \texttt{lat} : The coordinates of the observation in decimal degrees

\item {} 
\texttt{t} : Time in decimal years. This is only required for spatiotemporal models.

\end{itemize}

All other columns are interpreted as covariates, eg \texttt{ndvi} etc., UNLESS the module
implements the \texttt{non{\_}cov{\_}columns} attribute. For example, MBGWorld expects
lo{\_}age, up{\_}age columns, pos and neg columns, but does not interpret them as covariates.

\end{list}


%___________________________________________________________________________



\subsubsection{Options}
\label{sec:options}
\begin{itemize}
\item {} 
\texttt{-t} or \texttt{-{}-thin} : If thin is 10, every 10th MCMC iteration will be stored in the
database. Small values are good but slow. 1 is best.

\item {} 
\texttt{-i} or \texttt{-{}-iter} : The number of MCMC iterations to perform. Large values are good
but slow.

\item {} 
\texttt{-n} or \texttt{-ncpus} : The maximum number of CPU cores to make available to the MCMC
algorithm. Should be less than or equal to the number of cores in your computer. The
All the cores you make available may not be utilized. Use top or the Activity Monitor
to monitor your actual CPU usage. Large values are good but tie up more of your computer.

\end{itemize}


%___________________________________________________________________________



\subsection{\texttt{mbg-describe-tracefile}}
\label{sec:mbg-describe-tracefile}
\begin{quote}{\ttfamily \raggedright \noindent
mbg-describe-tracefile~path
}\end{quote}

If path is a database file, inspects the database file. Prints out the version of the
generic package, the module that produced the file and the date the run was started.
Writes the input data to csv with filename \texttt{database-file-input-csv}, substituting
the actual filename.

If the path is a directory, walks the filesystem starting from the directory, inspecting
every database file it finds. Does not produce any csvs.


%___________________________________________________________________________



\subsubsection{Required arguments}
\label{sec:id1}
\setcounter{listcnt0}{0}
\begin{list}{\arabic{listcnt0}.}
{
\usecounter{listcnt0}
\setlength{\rightmargin}{\leftmargin}
}
\item {} 
The name of the database file or path to be inspected.

\end{list}


%___________________________________________________________________________



\subsection{\texttt{mbg-covariate-traces}}
\label{sec:mbg-covariate-traces}
\begin{quote}{\ttfamily \raggedright \noindent
mbg-covariate-traces~module~database-file~{[}options{]}
}\end{quote}

Postprocesses the given database file to produce MCMC traces for the covariate
coefficients. Produces a directory called database-file-covariate-traces, and populates
it with pdf images of the covariate coefficient traces and


%___________________________________________________________________________



\subsubsection{Required arguments}
\label{sec:id2}
\setcounter{listcnt0}{0}
\begin{list}{\arabic{listcnt0}.}
{
\usecounter{listcnt0}
\setlength{\rightmargin}{\leftmargin}
}
\item {} 
The name of the module containing the model specification.

\item {} 
The name of the database file containing the MCMC trace.

\end{list}


%___________________________________________________________________________



\subsubsection{Options}
\label{sec:id3}
\begin{itemize}
\item {} 
\texttt{-t} or \texttt{-{}-thin} : If thin is 10, samples of the covariate coefficients will be
produced for every 10th MCMC sample. Defaults to 1, meaning no thinning.

\item {} 
\texttt{-b} or \texttt{-{}-burn} : Samples of the covariate coefficients will begin after this
many 'burnin' iterations are discarded. Defaults to 0, meaning no burnin.

\end{itemize}


%___________________________________________________________________________



\subsection{\texttt{mbg-decluster}}
\label{sec:mbg-decluster}
\begin{quote}{\ttfamily \raggedright \noindent
mbg-decluster~input~prop~{[}options{]}
}\end{quote}

A wrapper for the R function getdeclusteredsample that results in two new tables with
suffix HOLDOUT and THINNED outut to same directory as tablepath


%___________________________________________________________________________



\subsubsection{Required arguments}
\label{sec:id4}
\setcounter{listcnt0}{0}
\begin{list}{\arabic{listcnt0}.}
{
\usecounter{listcnt0}
\setlength{\rightmargin}{\leftmargin}
}
\item {} 
(string) path to input table. must include columns 'lon' and 'lat'. If
also 't' will treat as space-time. If only filename given (no path) assumes file
in current working directory.

\item {} 
(float) what proportion of the full data set will be used for hold-out set.

\end{list}


%___________________________________________________________________________



\subsubsection{Options}
\label{sec:id5}
\begin{itemize}
\item {} 
\texttt{-m} or \texttt{-{}-minsample} : (int) optional minimum sample size (supercedes prop.
if larger)

\item {} 
\texttt{-d} or \texttt{-{}-decluster} : (logical) do we want to draw spatially declustered
sample (default) or just simple random.

\item {} 
\texttt{-p} or \texttt{-{}-makeplot} : (logical) do we want to export a pdf map showing
location of data and selected points. This is exported to same directory as
tablepathoptional minimum sample size (supercedes prop if larger).

\end{itemize}


%___________________________________________________________________________



\subsection{\texttt{mbg-map}}
\label{sec:mbg-map}
\begin{quote}{\ttfamily \raggedright \noindent
mbg-map~module~database-file~burn~mask~{[}options{]}
}\end{quote}

Produces a folder called \texttt{name-maps} where \texttt{name} is the name of the database file.
Puts the requested maps in the folder in ascii format. Also produces PDF images of all
the requested maps for quick viewing.


%___________________________________________________________________________



\subsubsection{Required arguments}
\label{sec:id6}
\setcounter{listcnt0}{0}
\begin{list}{\arabic{listcnt0}.}
{
\usecounter{listcnt0}
\setlength{\rightmargin}{\leftmargin}
}
\item {} 
The name of the module containing the model specification.

\item {} 
The name of the database file (produced by mbg-infer) to be used to generate the
maps. If you do not want it to go in the current directory, specify a path.

\item {} 
The number of burnin iterations to discard from the trace before making the maps.
You will need to figure this out by inspecting the traces produced by \texttt{mbg-infer}.

\item {} 
The name of an ASCII file. The maps will be produced in ASCII files with identical
headers and identical MISSING pixels. If the file is in a different directory, specify
the path to it.

\end{list}


%___________________________________________________________________________



\subsubsection{Options}
\label{sec:id7}
\begin{itemize}
\item {} 
\texttt{-n} or \texttt{-{}-n-bins} : The number of bins to use in the histogram from which quantiles
are computed. Large values are good, but use up more system memory. Decrease this if you
see memory errors.

\item {} 
\texttt{-b} or \texttt{-{}-bufsize} : The number of buffer pixels to render around the edges of the
continents. Set to zero unless the \texttt{raster-thin} option is greater than 1. The buffer
will not be very good. In general, if you want a buffer you're better off making your
own in ArcView rather than using this option.

\item {} 
\texttt{-q} or \texttt{-{}-quantiles} : A string containing the quantiles you want. For example,
\texttt{'0.25 0.5 0.75'} would map the lower and upper quartiles and the medial. Default is
\texttt{'0.05 0.25 0.5 0.75 0.95'}.

\item {} 
\texttt{-r} or \texttt{-{}-raster-thin} : If you just want a quick preview, you can use this option to
render the maps on a degraded grid, then interpolate back to the original grid using splines.
For instance, if your input ASCII is on a 5km grid, and you use \texttt{-r 5}, the maps will be
rendered on a 25km grid, then interpolated back to a 5km grid when it is time to produce
the output ASCIIs. Small values are good but slow. 1 is best.

WARNING: The \texttt{raster{\_}thin} argument has been implicated in some odd-looking results and
should only be used for quick previews.

\item {} 
\texttt{-t} or \texttt{-{}-thin} : The factor by which to thin the MCMC trace stored in the database.
If you use \texttt{-t 10}, only every 10th stored MCMC iteration will be used to produce the maps.
Small values are good but slow. 1 is best.

\item {} 
\texttt{-i} or \texttt{-{}-iter} : The total number of predictive samples to use in generating the maps.
Large values are good but slow. Defaults to 20000.

\item {} 
\texttt{-a} or \texttt{-{}-ascii-path} : The path to the ASCII files containing the covariate rasters.
These files' headers must match those of the input raster, and their missing pixels must match
those of the input raster also. There must be a file corresponding to every covariate column
in input 3 of mbg-infer. For example, if you used \texttt{rain} and \texttt{ndvi} as your column headers,
files \texttt{rain.asc} and \texttt{ndvi.asc} in the ascii path should be present in the ascii path.
Defaults to the current working directory.

\item {} 
\texttt{-y} or \texttt{-{}-year} : If your model is spatiotemporal, you must provide the decimal year at
which you want your map produced. For example, Jan 1 2008 would be \texttt{-y 2008}.

\end{itemize}


%___________________________________________________________________________



\subsection{\texttt{mbg-validate}}
\label{sec:mbg-validate}
\begin{quote}{\ttfamily \raggedright \noindent
mbg-validate~module~database-file~burn~pred-pts~{[}options{]}
}\end{quote}

mbg-validate produces a folder called \texttt{name-validation}, \texttt{name} being the name of the database file.
It populates this folder with two csv files called \texttt{p-samps} and \texttt{n-samps} containing posterior
predictive samples of the probability of positivity and the number of individuals positive at each
prediction location.

It also writes three of the four MBG world validation panels into the folder as PDF's.


%___________________________________________________________________________



\subsubsection{Required arguments}
\label{sec:id8}
\setcounter{listcnt0}{0}
\begin{list}{\arabic{listcnt0}.}
{
\usecounter{listcnt0}
\setlength{\rightmargin}{\leftmargin}
}
\item {} 
The name of the module containing the model specification.

\item {} 
The name of the database file (produced by mbg-infer) to be used to generate the
maps. If you do not want it to go in the current directory, specify a path.

\item {} 
The number of burnin iterations to discard from the trace before making the maps.
You will need to figure this out by inspecting the traces produced by \texttt{mbg-infer}.

\item {} 
A csv file containing the 'holdout' dataset. It should be in exactly the same format
as the third required input to \texttt{mbg-infer}.

\end{list}


%___________________________________________________________________________



\subsubsection{Options}
\label{sec:id9}
\begin{itemize}
\item {} 
\texttt{-t} or \texttt{-{}-thin} : The factor by which to thin the MCMC trace stored in the database.
Small values are good but slow. 1 is best.

\item {} 
\texttt{-i} or \texttt{-{}-iter} : The total number of predictive samples you want to generate. Large
values are good but slow. Defaults to 20000.

\end{itemize}


%___________________________________________________________________________



\subsection{\texttt{mbg-scalar-priors}}
\label{sec:mbg-scalar-priors}
\begin{quote}{\ttfamily \raggedright \noindent
mbg-scalar-priors~module~{[}options{]}
}\end{quote}


%___________________________________________________________________________



\subsubsection{Required arguments}
\label{sec:id10}
\setcounter{listcnt0}{0}
\begin{list}{\arabic{listcnt0}.}
{
\usecounter{listcnt0}
\setlength{\rightmargin}{\leftmargin}
}
\item {} 
The name of the module containing the model specification.

\end{list}


%___________________________________________________________________________



\subsubsection{Options}
\label{sec:id11}
\begin{itemize}
\item {} 
\texttt{-i} or \texttt{-{}-iter} : The total number of predictive samples you want to generate. Large
values are good but slow. Defaults to 20000.

\end{itemize}


%___________________________________________________________________________



\subsection{\texttt{mbg-realize-prior}}
\label{sec:mbg-realize-prior}
\begin{quote}{\ttfamily \raggedright \noindent
mbg-realize-prior~module~ascii0.asc~ascii1.asc~...~{[}options{]}
}\end{quote}

mbg-realize-prior produces a number of prior realizations of the target surface (eg parasite
rate, gene frequency, etc). on several different asciis. Joint or 'conditional' simulations
of surfaces are very expensive, so you can only afford to evaluate them on a few thousand
pixels.

The multiple asciis are meant to be at multiple resolutions: you can make a coarse one over
your entire area of interest, a medium-resolution one on a zoomed-in subset, and a few fine
ones over small areas scattered around. That way you can see the large- and small-scale
properties of the surface allowed by your prior without having to render the entire surface
at full resolution.

Outputs a number of surfaces, evaluated onto the masks indicated by the input asciis. Each set
of realizations is coherent across the input asciis; that is, the 'same' surface is evaluated
on each ascii. That means you can meaningfully overlay the output asciis at different
resolutions.

NOTE: All the parameters of the model will be drawn from the prior before generating each
realization. If you want to fix a variable, you must set its \texttt{observed} flag.


%___________________________________________________________________________



\subsubsection{Required arguments}
\label{sec:id12}
\setcounter{listcnt0}{0}
\begin{list}{\arabic{listcnt0}.}
{
\usecounter{listcnt0}
\setlength{\rightmargin}{\leftmargin}
}
\item {} 
The name of the module containing the model specification.

\item {} 
Several ascii files. Realizations will be evaluated on the union of the unmasked regions
of these files.

\end{list}


%___________________________________________________________________________



\subsubsection{Options}
\label{sec:id13}
\begin{itemize}
\item {} 
\texttt{-n} or \texttt{-{}-n-realizations} : The number of realizations to generate. Defaults to 5.

\item {} 
\texttt{-m} or \texttt{-{}-mean} : The value of the global mean to use. Defaults to 0.

\item {} 
\texttt{-y} or \texttt{-year} : If your model is spatiotemporal, you must provide the decimal year at
which you want your realizations produced. For example, Jan 1 2008 would be \texttt{-y 2008}.

\end{itemize}


%___________________________________________________________________________



\subsection{Module requirements}
\label{sec:module-requirements}

This section tells you how to write new modules that will work with the shell commands.
You don't need to read this section to use the shell commands.


%___________________________________________________________________________



\subsubsection{\texttt{make{\_}model}}
\label{sec:make-model}

The primary thing a module must do to use the generic stuff is implement the function:
\begin{quote}{\ttfamily \raggedright \noindent
make{\_}model(pos,~neg,~lon,~lat,~{[}t{]},~covariate{\_}values,~cpus=1,~**non{\_}covariate{\_}columns)
}\end{quote}

The \texttt{pos}, \texttt{neg}, \texttt{lon} and \texttt{lat} columns are the obvious; longitude and
latitude should be in decimal degrees. The \texttt{t} column is only required for
spatiotemporal models, but if given it should be in units of decimal years.
The \texttt{cpus} argument specifies how many processor cores should be made available to
the current process.

The covariate values should be a dict of \texttt{{\{}name: column{\}}} pairs. If there are no covariates,
it should be expected to be empty. Modules should NOT use the covariates directly; rather
they should pass them to the function \texttt{cd{\_}and{\_}C{\_}eval} to be incorporated into the
covariance function. While on the topic, the trivial mean function and its evaluation
should be generated using \texttt{M{\_}and{\_}M{\_}eval}.

The non-covariate columns are any point metadata that are required by the model, but are
not covariates. Examples are \texttt{lo{\_}age} and \texttt{up{\_}age} in MBGWorld. These columns must
take defaults, as no values will be provided by \texttt{mbg-map}, \texttt{mbg-realize-prior} and
\texttt{mbg-scalar-priors}.

The model must be based on a Gaussian random field. The only hard requirements are that
it contain variables named \texttt{M} and \texttt{C} returning the mean and covairance function,
and that the data depend on these via evaluation at a \texttt{data mesh}, possibly with
addition of unstructured random noise involved at some point.


%___________________________________________________________________________



\subsubsection{Other attributes}
\label{sec:other-attributes}

The module must implement the following additional attributes:
\begin{itemize}
\item {} 
\texttt{f{\_}labels} : The names of the evaluations of the random fields in the model. These nodes'
traces will be used to generate predictions.

\item {} 
\texttt{x{\_}labels} : A dictionary mapping the \texttt{f{\_}labels} to the name of the mesh on which
the corresponding field is evaluated to produce the previous node. The value of the
mesh is expected to be present in the hdf5 archive's metadata. If it is not \texttt{logp{\_}mesh}
or \texttt{data{\_}mesh}, it should be mentioned in the \texttt{metadata{\_}keys} attribute.

\item {} 
\texttt{fs{\_}have{\_}nugget} : A dictionary of booleans indicating whether the \texttt{f{\_}labels} nodes are
just the evaluation of the corresponding field, or the evaluation plus the nugget.

\item {} 
\texttt{nugget{\_}names} : A dictionary mapping \texttt{f{\_}labels} to the names of the nugget variances of
the fields. Can be \texttt{None} for fields where \texttt{fs{\_}have{\_}nugget} is false.

\item {} 
\texttt{M{\_}labels} : A dictionary mapping \texttt{f{\_}labels} to the names of the means of the fields.

\item {} 
\texttt{C{\_}labels} : A dictionary mapping \texttt{f{\_}labels} to the names of the covariances of the
fields.

\item {} 
\texttt{diags{\_}safe} : A dictionary mapping \texttt{f{\_}labels} to booleans indicating whether it is safe
to assume \texttt{C(x) = C.params{[}'amp'{]}**2}.

\item {} 
\texttt{metadata{\_}keys} : A list of strings indicating the attributes of the model that should be
interred in the metadata. These are recorded as PyTables variable-length arrays with object
atoms, so they can be any picklable objects.

\item {} 
\texttt{non{\_}cov{\_}columns} : A dictionary of \texttt{{\{}name : type{\}}} mappings for all the point metadata
required by \texttt{make{\_}model} that are not covariates.

\item {} 
\texttt{mcmc{\_}init} : A function to be applied to the assembled model, before sampling begins.
May be used to assign step methods etc.

\item {} 
\texttt{map{\_}postproc} : When mapping and predicting, \texttt{make{\_}model} is not called. Rather, the mean
and covariance are pulled out of the trace and used to generate field realizations, with nugget
added as appropriate.

At the prediction stage, \texttt{postproc} is the function that translates these Gaussian
realizations to realizations of the target quantity. The most common \texttt{postproc} is simply
\texttt{invlogit}. The generic mbg package provides a multithreaded, shape-preserving invlogit
function that should be used in place of PyMC's.

The function should take keyword arguments corresponding to the module's \texttt{f{\_}labels}. It may
take additional keyword arguments corresponding to model variables, in which case the values
corresponding to each iteration will be pulled out of the trace. It should not take any non-
keyword arguments, contain any default values or take any variable arguments.

\item {} 
\texttt{validate{\_}postproc} : A function called with the non-covariate columns as keyword arguments.
It should return a version of map{\_}postproc that is closed on these values as defaults. For example,
for MBGWorld, \texttt{postproc} would accept \texttt{lo{\_}age} and \texttt{up{\_}age} values as input and return a
closure that accepts a single random field, \texttt{eps{\_}p{\_}f}, as a keyword argument. The latter would
take Gaussian realizations, pass them through the inverse-logit function, and multiply
age-correction factors as needed.

\end{itemize}

The following attributes are optional:
\begin{itemize}
\item {} 
\texttt{extra{\_}reduce{\_}fns} : A list of reduction functions to be used in mapping. These should take two
arguments, the first being the product so far and the second being a realization surface. The
first argument will be None at the first call. The return value should be a new value for the
first argument: an updated product so far.

\item {} 
\texttt{extra{\_}finalize} : A function converting the products of the extra reduce functions to output
asciis. It should take two arguments, the first being a \texttt{{\{}fn : prod{\}}} dictionary where \texttt{fn}
is one of the extra reduce functions and \texttt{prod} is its final output; and the second being the
total number of realization surfaces produced. The output should be a \texttt{{\{}name : surface{\}}}
dictionary, where all of the 'surfaces' are vectors ready to be injected into the mask and
written out as ascii files.

\end{itemize}

The \texttt{make{\_}model} function must create the following local variables, which will be interred
in the trace's metadata:
\begin{itemize}
\item {} 
\texttt{covariate{\_}dicts} : A dictionary mapping the \texttt{f{\_}label`{}`s to the result of the corresponding
call to `{}`cd{\_}and{\_}C{\_}eval}

\item {} 
All labels mentioned in the \texttt{x{\_}labels} and \texttt{metadata{\_}keys} items mentioned above.

\end{itemize}


%___________________________________________________________________________



\subsubsection{Version logging and installations}
\label{sec:version-logging-and-installations}

To avoid unpleasantness when restarting projects after leaving them for a long time in the future,
the SHA1 hash of the active commit of generic{\_}mbg and the specialization module will be written into
the trace hdf5 by mbg-infer.

For this to work correctly, generic{\_}mbg has to be installed using \texttt{setup.py install} and the
specialization module using \texttt{setup.py develop}.

