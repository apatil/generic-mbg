# Copyright (C) 2009 Anand Patil
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from optparse import OptionParser
import os

# Create option parser

req_doc = """

mbg-infer  Copyright (C) 2009 Anand Patil
This program comes with ABSOLUTELY NO WARRANTY.
This is free software, and you are welcome to redistribute it under certain conditions.
See <http://www.gnu.org/licenses/> for the terms of the license.


  module                The module from which maps are to be generated.
  database-file         The name of the database file to be produced.
  input                 A csv file containing the lon, lat, (time,) and 
                        associated covariate values.
                        
                        NOTE: time must be in units of DECIMAL YEARS SINCE
                        2009. That means it will usually be negative. That
                        is OK.
"""

p = OptionParser('usage: %prog module database-file input [options]' + req_doc)
p.add_option('-t','--thin',help='How much to thin the MCMC trace. Defaults to 10.',dest='thin',type='int')
p.add_option('-i','--iter',help='The total number of MCMC iterations to conduct. Defaults to 50000',dest='total',type='int')
p.add_option('-n','--ncpus',help='Number of CPU cores to make available to the MCMC',dest='ncpus',type='int')
p.add_option('-d','--delay',help='Delay iterations for AdaptiveMetropolis instance',dest='AM_delay',type='int')

p.set_defaults(thin=10)
p.set_defaults(total=100000)
p.set_defaults(AM_delay=5000)
p.set_defaults(ncpus=int(os.environ['OMP_NUM_THREADS']))

(o, args) = p.parse_args()
if len(args) != 3:
    raise IOError, 'You must supply exactly three positional arguments. You supplied %i.'%len(args)

o.module, o.hf_name, o.input_name = args

os.environ['OMP_NUM_THREADS']=str(o.ncpus)

import matplotlib
matplotlib.use('PDF')
matplotlib.interactive(False)

from map_utils import *
from generic_mbg import *
import tables as tb
import numpy as np
import imp, sys
import pymc as pm
from pylab import csv2rec, rec2csv
import pylab as pl
import time, datetime
import sys, subprocess

pm.set_threadpool_size(o.ncpus)


# Figure out what the database file is supposed to be

hf_path, hf_basename  = os.path.split(o.hf_name)    
prev_db = None
if hf_path=='':
    hf_path='./'
if hf_basename in os.listdir(hf_path):
    rm_q = raw_input('\nDatabase file %s already exists in path %s. Do you want to continue sampling? [yes or no] '%(hf_basename, hf_path))    
    if rm_q.strip() in ['y','YES','Yes','yes','Y']:
        prev_db = pm.database.hdf5.load(os.path.join(hf_path,hf_basename))
    elif rm_q.strip() in ['n','NO','No','no','N']:
        rm_q = raw_input('\nDo you want me to remove the file and start fresh? [yes or no] ')
        if rm_q.strip() in ['y','YES','Yes','yes','Y']:
            print '\nExcellent.'
            os.remove(o.hf_name)
        elif rm_q.strip() in ['n','NO','No','no','N']:
            raise OSError, '\nPlease sort yourself out.'
        else:
            raise OSError, '\nI do not know what you are trying to say. Move, rename or delete the database to continue.'


# Load up given module and load its relevant contents

mod_path, mod_name = os.path.split(o.module)
mod_basename, mod_ext = os.path.splitext(mod_name)
mod_search_path = [mod_path, os.getcwd()] + sys.path
mod = imp.load_module(mod_basename, *imp.find_module(mod_basename, mod_search_path))

# Get revision

curdir = os.getcwd()
os.chdir(os.path.join(mod.__path__[0],'..'))
process = subprocess.Popen('git show --pretty=format:"%H" --quiet', stdout=subprocess.PIPE, shell=True)
os.waitpid(process.pid, 0)
mod_commit = process.stdout.read().strip()

os.chdir(curdir)

for n in ['make_model', 'metadata_keys']:
    try:
        exec("%s=getattr(mod,'%s')"%(n,n))
    except:
        cls,inst,tb = sys.exc_info()
        new_inst = cls('Could not import %s from %s. Tell Anand. Original error message:\n\n\t%s'%(n,mod_name,inst.message))
        raise cls,new_inst,tb


# Parse input file

input = csv2rec(file(o.input_name,'U'))
from numpy.ma import mrecords
if isinstance(input, np.ma.mrecords.MaskedRecords):
    msg = 'Error, could not parse input at following rows:\n'
    for name in input.dtype.names:
        if np.sum(input[name].mask)>0:
            msg += '\t%s: %s\n'%(name, str(np.where(input[name].mask)[0]+1))
    raise ValueError, msg

lon = maybe_convert(input, 'lon', 'float')
lat = maybe_convert(input, 'lat', 'float')
mod_inputs = (lon,lat)
if hasattr(input, 't'):
    t = maybe_convert(input, 't', 'float')
    x = combine_st_inputs(lon,lat,t)
    mod_inputs = mod_inputs + (t,)
else:
    x = combine_spatial_inputs(lon,lat)
        
non_cov_columns = {'cpus': o.ncpus}
if hasattr(mod, 'non_cov_columns'):
    non_cov_coltypes = mod.non_cov_columns
else:
    non_cov_coltypes = {}
non_cov_colnames = non_cov_coltypes.keys()

covariate_dict = {}
for n in input.dtype.names:
    if n not in ['lon','lat','t']:
        if n in non_cov_colnames:
            non_cov_columns[n] = maybe_convert(input, n, non_cov_coltypes[n])
        else:
            covariate_dict[n]=maybe_convert(input, n, 'float')

mod_inputs = mod_inputs + (covariate_dict,)

# Create MCMC object, add metadata, and assign appropriate step method.

if hf_path != '':
    os.chdir(hf_path)
if prev_db is None:
    M = pm.MCMC(make_model(*mod_inputs,**non_cov_columns),db='hdf5',dbname=hf_basename,complevel=1,complib='zlib')
    add_standard_metadata(M, M.logp_mesh, M.data_mesh, M.covariate_dict, **(dict(zip(metadata_keys, [getattr(M,k) for k in metadata_keys]))))
    M.db._h5file.createTable('/','input_csv',csv2rec(file(o.input_name,'U')))
    M.db._h5file.root.input_csv.attrs.shellargs = ' '.join(sys.argv[1:])
    M.db._h5file.root.input_csv.attrs.mod_name = mod_name
    M.db._h5file.root.input_csv.attrs.mod_commit = mod_commit
    M.db._h5file.root.input_csv.attrs.generic_commit = generic_commit
    M.db._h5file.root.input_csv.attrs.starttime = datetime.datetime.now()
    M.db._h5file.root.input_csv.attrs.input_filename = o.input_name
    
else:
    M = pm.MCMC(make_model(*mod_inputs,**non_cov_columns),db=prev_db)
    M.restore_sampler_state()
scalar_stochastics = filter(lambda s: len(np.atleast_1d(s.value)) == 1, M.stochastics)
scale_dict = dict(zip(scalar_stochastics, .001*np.ones(len(scalar_stochastics))))


if hasattr(M, 'f'):
    if hasattr(M,'ti'):
        ti = M.ti
    else:
        ti = np.arange(M.logp_mesh.shape[0])
    M.use_step_method(FieldStepper, M.f, M.V, M.C_eval, M.M_eval, M.logp_mesh, M.eps_p_f, ti)

M.use_step_method(pm.AdaptiveMetropolis, scalar_stochastics, scales=scale_dict, delay=o.AM_delay)
for s in M.stochastics:
    if s not in scalar_stochastics and s.__name__ != 'f':
        M.use_step_method(pm.AdaptiveMetropolis, s, scales={s: .0001*np.ones(np.shape(s.value))}, delay=o.AM_delay)

M.assign_step_methods()        
if prev_db is not None:
    M.restore_sm_state()


# Run MCMC

t_start = time.time()
M.isample(o.total,0,o.thin)
print '\nMCMC completed in %f seconds\n'%(time.time() - t_start)


# Write out

base_outname = os.path.splitext(hf_basename)[0]
plot_dir = os.path.join(hf_path, base_outname+'-plots')
try:
    os.mkdir(plot_dir)
except OSError:
    pass
os.chdir(plot_dir)
for s in M._variables_to_tally:
    if np.prod(np.shape(s.value)) == 1 and M.trace(s.__name__)[0].dtype != np.dtype('object'):
        print 'Plotting %s'%s.__name__
        pl.clf()
        pl.plot(all_chain_trace(M.db._h5file, s.__name__))
        pl.title(s.__name__)
        pl.savefig(s.__name__+'.pdf')
